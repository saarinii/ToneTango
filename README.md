# ğŸµ ToneTango â€” Speech Emotion Recognition

![Python](https://img.shields.io/badge/Python-3.x-blue?logo=python)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow)
![Librosa](https://img.shields.io/badge/Librosa-Audio%20Processing-green)
![Status](https://img.shields.io/badge/Status-Active-success)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

ToneTango is a **Speech Emotion Recognition (SER)** system that detects human emotions from voice inputs using a **CNN-based deep learning** model.  
It processes audio, extracts features like **MFCC**, **Chroma**, and **Mel Spectrogram**, and classifies emotions such as:

> ğŸ˜Š Happy | ğŸ˜¢ Sad | ğŸ˜¡ Angry | ğŸ˜¨ Fear | ğŸ˜– Disgust | ğŸ˜ Neutral | ğŸ˜Œ Calm | ğŸ˜² Surprised

---

## ğŸš€ Features

- ğŸ¤ Audio preprocessing & augmentation *(noise addition, pitch shift, time stretch)*
- ğŸ“‚ Integration of **RAVDESS**, **TESS**, **CREMA-D**, and **SAVEE** datasets
- ğŸ§  CNN architecture for high-accuracy classification
- ğŸ“ˆ Achieves **~85% accuracy** on test data
- ğŸ”Œ Modular code for easy extension & real-time applications

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python 3.x
- **Libraries:** TensorFlow/Keras, Librosa, NumPy, Pandas, Scikit-learn, Matplotlib, Seaborn



1ï¸âƒ£ Clone the repository  
```bash
git clone https://github.com/yourusername/ToneTango.git
cd ToneTango
```

2ï¸âƒ£ Install dependencies  
```bash
pip install -r requirements.txt
```

3ï¸âƒ£ Open **ToneTango.ipynb** to view the final implementation and run code  
```bash
jupyter notebook notebooks/ToneTango.ipynb
```

---

## ğŸ¯ Applications

- ğŸ¤– Virtual assistants  
- ğŸ“ Call center sentiment monitoring  
- ğŸ¥ Healthcare & mental wellness tracking  
- ğŸ“ Emotion-aware e-learning platforms  
- ğŸ® Gaming & interactive media  


---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” feel free to use and modify.

---

> ğŸ’¡ **Note:** For the complete implementation, refer to **`ToneTango.ipynb`** 
